\begin{thebibliography}{20}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bishop(2006)]{ml_bishop}
Christopher~M. Bishop.
\newblock \emph{Pattern Recognition and Machine Learning (Information Science
  and Statistics)}.
\newblock Springer-Verlag New York, Inc., Secaucus, NJ, USA, 2006.
\newblock ISBN 0387310738.

\bibitem[Bottou(2012)]{bottou2012stochastic}
L{\'e}on Bottou.
\newblock Stochastic gradient descent tricks.
\newblock In \emph{Neural Networks: Tricks of the Trade}, pages 421--436.
  Springer, 2012.

\bibitem[Bousquet and Bottou(2008)]{bousquet2008tradeoffs}
Olivier Bousquet and L{\'e}on Bottou.
\newblock The tradeoffs of large scale learning.
\newblock In \emph{Advances in neural information processing systems}, pages
  161--168, 2008.

\bibitem[climin developers(2013)]{climin-rmsprop}
climin developers.
\newblock rmsprop.
\newblock
  \url{http://climin.readthedocs.org/en/latest/rmsprop.html\#tieleman2012rmsprop},
  2013.
\newblock Accessed: 2014-11-24.

\bibitem[Glorot and Bengio(2010)]{glorot2010understanding}
Xavier Glorot and Yoshua Bengio.
\newblock Understanding the difficulty of training deep feedforward neural
  networks.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 249--256, 2010.

\bibitem[Hinton et~al.(2014)Hinton, Srivastava, and Swersky]{hinton-nnml-2014}
Geoff Hinton, Nitish Srivastava, and Kevin Swersky.
\newblock Neural networks for machine learning.
\newblock 2014.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and
  Hinton]{krizhevsky2012imagenet}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In \emph{Advances in neural information processing systems}, pages
  1097--1105, 2012.

\bibitem[Lab(2011)]{pylearn2-training}
LISA Lab.
\newblock Training -- pylearn2 dev documentation.
\newblock \url{http://deeplearning.net/software/pylearn2/library/train.html},
  2011.
\newblock Accessed: 2014-12-08.

\bibitem[LeCun et~al.(1998{\natexlab{a}})LeCun, Bottou, Bengio, and
  Haffner]{lecun-98}
Y.~LeCun, L.~Bottou, Y.~Bengio, and P.~Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0
  2278--2324, November 1998{\natexlab{a}}.

\bibitem[LeCun et~al.(1998{\natexlab{b}})LeCun, Bottou, Orr, and
  Muller]{lecun-98b}
Y.~LeCun, L.~Bottou, G.~Orr, and K.~Muller.
\newblock Efficient backprop.
\newblock In G.~Orr and Muller K., editors, \emph{Neural Networks: Tricks of
  the trade}. Springer, 1998{\natexlab{b}}.

\bibitem[Martens(2010)]{martens2010deep}
James Martens.
\newblock Deep learning via hessian-free optimization.
\newblock In \emph{Proceedings of the 27th International Conference on Machine
  Learning (ICML-10)}, pages 735--742, 2010.

\bibitem[Martens and Sutskever(2012)]{martens-hf-guide}
James Martens and Ilya Sutskever.
\newblock Training deep and recurrent neural networks with hessian-free
  optimization.
\newblock In \emph{Neural Networks: Tricks of the Trade}, 2012.

\bibitem[Mohri et~al.(2012)Mohri, Rostamizadeh, and Talwalkar]{ml_mohri}
Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar.
\newblock \emph{Foundations of Machine Learning}.
\newblock The MIT Press, 2012.
\newblock ISBN 026201825X, 9780262018258.

\bibitem[Nair and Hinton(2010)]{nair2010rectified}
Vinod Nair and Geoffrey~E Hinton.
\newblock Rectified linear units improve restricted boltzmann machines.
\newblock In \emph{Proceedings of the 27th International Conference on Machine
  Learning (ICML-10)}, pages 807--814, 2010.

\bibitem[Ng et~al.(2013)Ng, Ngiam, Foo, Mai, Suen, Coates, Maas, Hannun, Huval,
  Wang, and Tandon]{ufldl-website}
Andrew Ng, Jiquan Ngiam, Chuan~Yu Foo, Yifan Mai, Caroline Suen, Adam Coates,
  Andrew Maas, Awni Hannun, Brody Huval, Tao Wang, and Sameep Tandon.
\newblock Unsupervised feature learning and deep learning tutorial.
\newblock \url{http://ufldl.stanford.edu/tutorial/}, 2013.
\newblock Accessed: 2014-11-24.

\bibitem[Ngiam et~al.(2011)Ngiam, Coates, Lahiri, Prochnow, Le, and
  Ng]{ngiam2011optimization}
Jiquan Ngiam, Adam Coates, Ahbik Lahiri, Bobby Prochnow, Quoc~V Le, and
  Andrew~Y Ng.
\newblock On optimization methods for deep learning.
\newblock In \emph{Proceedings of the 28th International Conference on Machine
  Learning (ICML-11)}, pages 265--272, 2011.

\bibitem[Schaul et~al.(2013)Schaul, Zhang, and LeCun]{schaul-icml-13}
Tom Schaul, Sixin Zhang, and Yann LeCun.
\newblock No more pesky learning rates.
\newblock In \emph{Proc. International Conference on Machine learning
  (ICML'13)}, 2013.

\bibitem[Sutskever et~al.(2013)Sutskever, Martens, Dahl, and
  Hinton]{sutskever2013importance}
Ilya Sutskever, James Martens, George Dahl, and Geoffrey Hinton.
\newblock On the importance of initialization and momentum in deep learning.
\newblock In \emph{Proceedings of the 30th International Conference on Machine
  Learning (ICML-13)}, pages 1139--1147, 2013.

\bibitem[Zeiler(2012)]{zeiler2012adadelta}
Matthew~D Zeiler.
\newblock Adadelta: An adaptive learning rate method.
\newblock \emph{arXiv preprint arXiv:1212.5701}, 2012.

\bibitem[Zeiler and Fergus(2014)]{zeiler2014visualizing}
Matthew~D Zeiler and Rob Fergus.
\newblock Visualizing and understanding convolutional networks.
\newblock In \emph{Computer Vision--ECCV 2014}, pages 818--833. Springer, 2014.

\end{thebibliography}
